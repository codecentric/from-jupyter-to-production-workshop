{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Extend Kedro Pipeline\n",
    "\n",
    "In this exercise, you will get more familier with Kedro by extending the workflow pipeline shown in the introduction. Note that the introduction notebook should be run prior to this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first change the working directory to the existing project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/workshop/kedro_intro/workflow-tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask I: Add additional node to pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, it should be evaluated. Create a new Kedro `node` that takes as input the model, and the features `x_test` and target `y_test`.\n",
    "\n",
    "The output should be `evaluation_metric`: a json including several metrics.\n",
    "\n",
    "The following function can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_model(pipe: Pipeline, x_test: np.ndarray, y_test: np.ndarray):\n",
    "    \"\"\"Calculate the coefficient of determination and log the result.\n",
    "\n",
    "        Args:\n",
    "            pipe: Trained model.\n",
    "            X_test: Testing data of independent features.\n",
    "            y_test: Target.\n",
    "        Returns:\n",
    "            json with scores\n",
    "\n",
    "    \"\"\"\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"Model has a coefficient R^2 of %.3f.\", r2)\n",
    "\n",
    "    return {\"train\": {\"rmse\": float(rmse),\n",
    "                      \"mae\": float(mae),\n",
    "                      \"r2\": float(r2)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend existing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/workflow_tutorial/pipelines/pipeline.py\n",
    "\n",
    "from kedro.pipeline import Pipeline, node\n",
    "\n",
    "from .nodes import evaluate_model, split_data, train_model\n",
    "\n",
    "\n",
    "def create_pipeline(**kwargs):\n",
    "    return Pipeline(\n",
    "        [\n",
    "            node(\n",
    "                func=split_data,\n",
    "                inputs=[\"wines-red\", \"parameters\"],\n",
    "                outputs=[\"x_train\", \"x_test\", \"y_train\", \"y_test\"],\n",
    "                name=\"splitting_data\",\n",
    "            ),\n",
    "            node(\n",
    "                func=train_model,\n",
    "                inputs=[\"x_train\", \"y_train\", \"parameters\"],\n",
    "                outputs=\"model\",\n",
    "                name=\"training_model\",\n",
    "            ),\n",
    "            node(\n",
    "                func=evaluate_model,\n",
    "                inputs=[\"model\", \"x_test\", \"y_test\"],\n",
    "                outputs=\"evaluation_metric\",\n",
    "                name=\"evaluating_model\",\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and visualize pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kedro run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kedro viz --host=0.0.0.0 --no-browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask II: Add second pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data\n",
    "In the introduction, we have build a pipeline that predicts the quality of **red** wine.\n",
    "Let's now build a second Pipeline that predicts the quality of **white** wine.\n",
    "\n",
    "Download the [Wine Quality Data Set](http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv) for white wines and add the data to the corresponing directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data/01_raw/winequality-white.csv http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the datasets\n",
    "Register the dataset in the catalog!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conf/base/catalog.yml\n",
    "\n",
    "wines-red:\n",
    "  type: pandas.CSVDataSet\n",
    "  filepath: data/01_raw/winequality-red.csv\n",
    "  load_args:\n",
    "    sep: ';'\n",
    "\n",
    "wines-white:\n",
    "  type: pandas.CSVDataSet\n",
    "  filepath: data/01_raw/winequality-white.csv\n",
    "  load_args:\n",
    "    sep: ';'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "from kedro.framework.context import load_context\n",
    "\n",
    "context = load_context(Path.cwd())\n",
    "df = context.catalog.load(\"wines-white\")\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "profile.to_file(\"data/08_reporting/wines-white.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pipeline\n",
    "Create and registered the new pipeline in `src/workflow_tutorial/pipelines/` and `src/workflow_tutorial/hooks.py`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/workflow_tutorial/pipelines/pipeline.py\n",
    "\n",
    "from kedro.pipeline import Pipeline, node\n",
    "\n",
    "from .nodes import evaluate_model, split_data, train_model\n",
    "\n",
    "\n",
    "def create_red_wine_pipeline(**kwargs):\n",
    "    return Pipeline(\n",
    "        [\n",
    "            node(\n",
    "                func=split_data,\n",
    "                inputs=[\"wines-red\", \"parameters\"],\n",
    "                outputs=[\"x_train_red\", \"x_test_red\", \"y_train_red\", \"y_test_red\"],\n",
    "                name=\"splitting_red_wine_data\",\n",
    "            ),\n",
    "            node(\n",
    "                func=train_model,\n",
    "                inputs=[\"x_train_red\", \"y_train_red\", \"parameters\"],\n",
    "                outputs=\"model_red\",\n",
    "                name=\"training_red_wine_model\",\n",
    "            ),\n",
    "            node(\n",
    "                func=evaluate_model,\n",
    "                inputs=[\"model_red\", \"x_test_red\", \"y_test_red\"],\n",
    "                outputs=\"evaluation_metrics_red\",\n",
    "                name=\"evaluating_red_wine_model\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def create_white_wine_pipeline(**kwargs):\n",
    "    return Pipeline(\n",
    "        [\n",
    "            node(\n",
    "                func=split_data,\n",
    "                inputs=[\"wines-white\", \"parameters\"],\n",
    "                outputs=[\"x_train_white\", \"x_test_white\", \"y_train_white\", \"y_test_white\"],\n",
    "                name=\"splitting_white_wine_data\",\n",
    "            ),\n",
    "            node(\n",
    "                func=train_model,\n",
    "                inputs=[\"x_train_white\", \"y_train_white\", \"parameters\"],\n",
    "                outputs=\"model_white\",\n",
    "                name=\"training_white_wine_model\",\n",
    "            ),\n",
    "            node(\n",
    "                func=evaluate_model,\n",
    "                inputs=[\"model_white\", \"x_test_white\", \"y_test_white\"],\n",
    "                outputs=\"evaluation_metrics_white\",\n",
    "                name=\"evaluating_white_wine_model\",\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the pipeline\n",
    "\n",
    "Note that `register_pipelines` returns `Dict[str, Pipeline]`, hence, you can return multiple pipelines for each type of wine.\n",
    "\n",
    "The default pipeline usually comprises all possible pipelines: You can simply add `red_wine_pipeline + white_wine_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/workflow_tutorial/hooks.py\n",
    "\n",
    "\"\"\"Project hooks.\"\"\"\n",
    "from typing import Any, Dict, Iterable, Optional\n",
    "\n",
    "from kedro.config import ConfigLoader\n",
    "from kedro.framework.hooks import hook_impl\n",
    "from kedro.io import DataCatalog\n",
    "from kedro.pipeline import Pipeline\n",
    "from kedro.versioning import Journal\n",
    "\n",
    "from workflow_tutorial.pipelines import pipeline\n",
    "\n",
    "class ProjectHooks:\n",
    "    @hook_impl\n",
    "    def register_pipelines(self) -> Dict[str, Pipeline]:\n",
    "        \"\"\"Register the project's pipeline.\n",
    "\n",
    "        Returns:\n",
    "            A mapping from a pipeline name to a ``Pipeline`` object.\n",
    "\n",
    "        \"\"\"\n",
    "        red_wine_pipeline = pipeline.create_red_wine_pipeline()\n",
    "        white_wine_pipeline = pipeline.create_white_wine_pipeline()\n",
    "        \n",
    "        return {\n",
    "            \"red\": red_wine_pipeline,\n",
    "            \"white\": white_wine_pipeline,\n",
    "            \"__default__\": red_wine_pipeline + white_wine_pipeline,\n",
    "        }\n",
    "\n",
    "    @hook_impl\n",
    "    def register_config_loader(self, conf_paths: Iterable[str]) -> ConfigLoader:\n",
    "        return ConfigLoader(conf_paths)\n",
    "\n",
    "    @hook_impl\n",
    "    def register_catalog(\n",
    "        self,\n",
    "        catalog: Optional[Dict[str, Dict[str, Any]]],\n",
    "        credentials: Dict[str, Dict[str, Any]],\n",
    "        load_versions: Dict[str, str],\n",
    "        save_version: str,\n",
    "        journal: Journal,\n",
    "    ) -> DataCatalog:\n",
    "        return DataCatalog.from_config(\n",
    "            catalog, credentials, load_versions, save_version, journal\n",
    "        )\n",
    "\n",
    "\n",
    "project_hooks = ProjectHooks()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the parameters Parameters.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conf/base/parameters.yml\n",
    "test_size: 0.25\n",
    "random_state: 42\n",
    "\n",
    "alpha: 0.5\n",
    "l1_ratio: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "You can either run the full (default) project pipeline or a pipeline specified with the `--pipeline` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kedro run --pipeline=red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kedro run -p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kedro Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kedro viz --host=0.0.0.0 --no-browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Subtask: Add data version control\n",
    "Add git and data version control (DVC - already installed) to the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git init\n",
    "!dvc init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dvc remote storage (local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc remote add -d -f local_storage /tmp/kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now let's not track the mlflow runs..\n",
    "!echo $'\\nmlruns/**' >> .gitignore\n",
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, configure your git..\n",
    "#!git config --global user.email \"you@example.com\"\n",
    "#!git config --global user.name \"Your Name\"\n",
    "!git commit -m \"initial commit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could add data directly or as dependencies in a DVC pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!dvc add data/01_raw/winequality-red.csv\n",
    "#!dvc add data/01_raw/winequality-white.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the model pickle and the metrics file to the catalog in order to not only store them as a Kedro `MemoryDataSet` but locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conf/base/catalog.yml\n",
    "\n",
    "wines-red:\n",
    "  type: pandas.CSVDataSet\n",
    "  filepath: data/01_raw/winequality-red.csv\n",
    "  load_args:\n",
    "    sep: ';'\n",
    "\n",
    "wines-white:\n",
    "  type: pandas.CSVDataSet\n",
    "  filepath: data/01_raw/winequality-white.csv\n",
    "  load_args:\n",
    "    sep: ';'\n",
    "\n",
    "model_red:\n",
    "  type: pickle.PickleDataSet\n",
    "  filepath: data/06_models/model_red.pickle\n",
    "\n",
    "model_white:\n",
    "  type: pickle.PickleDataSet\n",
    "  filepath: data/06_models/model_white.pickle\n",
    "\n",
    "evaluation_metrics_red:\n",
    "  type: yaml.YAMLDataSet\n",
    "  filepath: data/08_reporting/scores_red.yaml\n",
    "    \n",
    "evaluation_metrics_white:\n",
    "  type: yaml.YAMLDataSet\n",
    "  filepath: data/08_reporting/scores_white.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dvc pipelines for red and white wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dvc run -n kedro_red \\\n",
    "        -p conf/base/parameters.yml:test_size,random_state,alpha,l1_ratio \\\n",
    "        -d data/01_raw/winequality-red.csv \\\n",
    "        -d src/workflow_tutorial/pipelines \\\n",
    "        -m data/08_reporting/scores_red.yaml \\\n",
    "        -o data/06_models/model_red.pickle \\\n",
    "        'kedro run --pipeline=red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dvc run -n kedro_white \\\n",
    "        -p conf/base/parameters.yml:test_size,random_state,alpha,l1_ratio \\\n",
    "        -d data/01_raw/winequality-white.csv \\\n",
    "        -d src/workflow_tutorial/pipelines \\\n",
    "        -m data/08_reporting/scores_white.yaml \\\n",
    "        -o data/06_models/model_white.pickle \\\n",
    "        'kedro run --pipeline=white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit your changes and update dvc remote storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"add dvc pipelines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc status -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything should now be up to date.                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status\n",
    "!dvc status -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Subtask: Create Airflow DAG from Kedro pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install more project dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the *kedro-airflow* plugin. Please install this new project dependency using `kedro install`.\n",
    "Note that to further update the project requirements, you should modify `src/requirements.in` (not `src/requirements.txt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile src/requirements.in\n",
    "#kedro-airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kedro install --build-reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kedro airflow create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kedro airflow deploy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
