{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "# Building a demand forecasting model using BigQuery ML\n",
    "\n",
    "In this notebook we show how a time series model can be trained, analysed and deployed using BigQuery ML. It provides an end-to-end solution for forecasting multiple products. Using the public dataset [Iowa Liquor Sales](https://console.cloud.google.com/marketplace/details/obfuscated-ga360-data/obfuscated-ga360-data?filter=solution-type:dataset), we build five time series models with a few SQL queries, each model predicting the retail sales of a single liquor product. \n",
    "\n",
    "By the end of this notebook, we will have learnt how to:\n",
    "* Prepare time series data into the correct format required to build the model.\n",
    "* Train a time series model in BigQuery ML.\n",
    "* Evaluate the model.\n",
    "* Make predictions about future demand using the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeWsN9G3ap9a",
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRUOFELefqf1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKeTQnDdap9n"
   },
   "source": [
    "### Plotting-Script (for later use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0rsmNE1ap9n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_historical_and_forecast(input_timeseries, \n",
    "                                 timestamp_col_name, \n",
    "                                 data_col_name, \n",
    "                                 forecast_output=None, \n",
    "                                 actual=None, \n",
    "                                 title=None,\n",
    "                                 plotstartdate=None):\n",
    "\n",
    "    if plotstartdate:\n",
    "        input_timeseries[timestamp_col_name] = pd.to_datetime(input_timeseries[timestamp_col_name])\n",
    "        input_timeseries = input_timeseries[input_timeseries[timestamp_col_name] >= pd.to_datetime(plotstartdate)]\n",
    "        \n",
    "    input_timeseries = input_timeseries.sort_values(timestamp_col_name)    \n",
    "    \n",
    "    # Plot the input historical data\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.plot(input_timeseries[timestamp_col_name], input_timeseries[data_col_name], label = 'Historical')\n",
    "    plt.xlabel(timestamp_col_name)\n",
    "    plt.ylabel(data_col_name)\n",
    "\n",
    "    if forecast_output is not None:\n",
    "        forecast_output = forecast_output.sort_values('forecast_timestamp')\n",
    "        forecast_output['forecast_timestamp'] = pd.to_datetime(forecast_output['forecast_timestamp'])\n",
    "        x_data = forecast_output['forecast_timestamp']\n",
    "        y_data = forecast_output['forecast_value']\n",
    "        confidence_level = forecast_output['confidence_level'].iloc[0] * 100\n",
    "        low_CI = forecast_output['confidence_interval_lower_bound']\n",
    "        upper_CI = forecast_output['confidence_interval_upper_bound']\n",
    "        # Plot the forecast data\n",
    "        plt.plot(x_data, y_data, alpha = 1, label = 'Forecast', linestyle='--')\n",
    "        # Shade the confidence interval\n",
    "        plt.fill_between(x_data, low_CI, upper_CI, color = '#539caf', alpha = 0.4, \n",
    "                         label = f'{confidence_level} confidence interval')\n",
    "\n",
    "    # Plot actual data\n",
    "    if actual is not None:\n",
    "        actual = actual.sort_values(timestamp_col_name)\n",
    "        plt.plot(actual[timestamp_col_name], actual[data_col_name], label = 'Actual', linestyle='--')   \n",
    "\n",
    "    # Display title, legend\n",
    "    plt.title(f'{title}', fontsize= 16)\n",
    "    plt.legend(loc = 'upper center', prop={'size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znIaF2QGsDkr"
   },
   "source": [
    "### Create a BigQuery dataset\n",
    "\n",
    "We need to specify `US` as location to be able to copy data from the public dataset into our dataset, which is also located in US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIBm-lrVsDks",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE SCHEMA IF NOT EXISTS\n",
    "bqmlforecast\n",
    "OPTIONS (\n",
    "    location=\"US\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QB7wXYDpsDkv"
   },
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsxSG7yfsDkv"
   },
   "source": [
    "We train the time series models on a dataset of transaction data. Each row represents a transaction for a single product, identified by the value `item_description`, and contains details such as the number of bottles sold and the sales amount in dollars. In the following steps, we use the value for the number of bottles sold to forecast product demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "cQlwqRKvap9u",
    "outputId": "9a97df3a-62c7-4e8e-8fef-01d4f8ff0d2f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT \n",
    "    invoice_and_item_number,\n",
    "    date,\n",
    "    store_number,\n",
    "    item_description,\n",
    "    bottles_sold,\n",
    "    sale_dollars\n",
    "FROM\n",
    "  `bigquery-public-data.iowa_liquor_sales.sales` \n",
    "LIMIT \n",
    "  5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFq6aLFBap9z"
   },
   "source": [
    "### Set start and end date of the train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWbaGiY-ap90"
   },
   "source": [
    "We can adjust the parameters `TRAININGDATA_STARTDATE` and `TRAININGDATA_ENDDATE` to specify the start/end date of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2cyW1P8ap90",
    "outputId": "7253e1fd-6164-438b-a30b-53c49e61d6b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ARIMA_PARAMS = {\n",
    "    'TRAININGDATA_STARTDATE': '2020-01-01',\n",
    "    'TRAININGDATA_ENDDATE': '2022-01-01',\n",
    "}\n",
    "ARIMA_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmz_Wh7yap93"
   },
   "source": [
    "### Write train data into a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1B5NDEfVL2C"
   },
   "source": [
    "Some days in the data have no transactions for a specific product. BigQueryML can automatically perform some typical pre-processing:\n",
    "\n",
    "* Missing values: values are imputed using local linear interpolation.\n",
    "* Duplicated timestamps: The values are averaged over duplicated timestamps.\n",
    "* Spike and dip anomalies: The values are standardised using local z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "7-bBYO-Hap93",
    "outputId": "59fd1987-a01b-4e3a-9719-456f790bedf3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --params $ARIMA_PARAMS\n",
    "\n",
    "CREATE OR REPLACE TABLE bqmlforecast.training_data AS (\n",
    "    WITH topsellingitems AS(\n",
    "         SELECT \n",
    "            item_description,\n",
    "            count(item_description) cnt_transactions\n",
    "        FROM\n",
    "            `bigquery-public-data.iowa_liquor_sales.sales` \n",
    "        GROUP BY \n",
    "            item_description\n",
    "        ORDER BY cnt_transactions DESC\n",
    "        LIMIT 5\n",
    "    )\n",
    "    SELECT \n",
    "        date,\n",
    "        item_description AS item_name,\n",
    "        SUM(bottles_sold) AS total_amount_sold\n",
    "    FROM\n",
    "        `bigquery-public-data.iowa_liquor_sales.sales` \n",
    "    GROUP BY\n",
    "        date, item_name\n",
    "    HAVING \n",
    "        date BETWEEN @TRAININGDATA_STARTDATE AND @TRAININGDATA_ENDDATE\n",
    "        AND item_description IN (SELECT item_description FROM topsellingitems)\n",
    "    );\n",
    "\n",
    "SELECT \n",
    "    date,\n",
    "    item_name,\n",
    "    total_amount_sold\n",
    "FROM \n",
    "    bqmlforecast.training_data \n",
    "ORDER BY item_name, date\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liuS8qCnap96"
   },
   "source": [
    "### Sales history of the target spirits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQxRDGLAap97"
   },
   "source": [
    "We store the training data in the Pandas dataframe `pdfhistorical`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwVPZP3fap97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery dfhistorical\n",
    "\n",
    "SELECT * FROM bqmlforecast.training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hCvY292Xap9-",
    "outputId": "3b464686-cc5a-4ad7-f860-860ffd919f17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "itemslist = list(dfhistorical.item_name.unique())\n",
    "\n",
    "for item in itemslist:\n",
    "    \n",
    "    datah = dfhistorical[dfhistorical.item_name==item]\n",
    "    plot_historical_and_forecast(input_timeseries = datah, \n",
    "                                 timestamp_col_name = \"date\",\n",
    "                                 data_col_name = \"total_amount_sold\", \n",
    "                                 forecast_output = None, \n",
    "                                 actual = None,\n",
    "                                 title = item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft6ioX_kap-A"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqGEpOzvW2pl"
   },
   "source": [
    "As the model is trained for multiple products in a single modelling statement, we specify the `item_name` column for the [TIME_SERIES_ID_COL](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-time-series#time_series_id_col) parameter. We do not need this information for a single target item.\n",
    "Further information on the SQL statement for creating models: [Documentation on creating BigQuery ML time series models](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-time-series#create_model_syntax).\n",
    "\n",
    "A common problem with time series data are holiday effects and seasonalities. BigQueryML can take this into account by specifying the `HOLIDAY_REGION`. By default, the modelling of holiday effects is deactivated. If holiday effects are activated, outliers that occur during public holidays are no longer treated as anomalies. Since we are analysing data from Iowa here, we set the `HOLIDAY_REGION` to `US`. However, there is also holiday data for other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 31
    },
    "id": "CibqJ8yVL6kS",
    "outputId": "6d8e6996-557a-4fd7-d8b1-22e8f3c9b075",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL bqmlforecast.arima_model\n",
    "\n",
    "OPTIONS(\n",
    "  MODEL_TYPE='ARIMA',\n",
    "  TIME_SERIES_TIMESTAMP_COL='date', \n",
    "  TIME_SERIES_DATA_COL='total_amount_sold',\n",
    "  TIME_SERIES_ID_COL='item_name',\n",
    "  HOLIDAY_REGION='US'\n",
    ") AS\n",
    "\n",
    "SELECT \n",
    "    date,\n",
    "    item_name,\n",
    "    total_amount_sold\n",
    "FROM\n",
    "  bqmlforecast.training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUkZYuZH-rn2"
   },
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vEV-65m-0QJ"
   },
   "source": [
    "We can use [ML.EVALUATE](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate) to display the quality metrics of all created models. \n",
    "\n",
    "The columns `non_seasonal_`{`p`,`d`,`q`} and `has_drift` define the time series model. The columns `log_likelihood`, `AIC` and `variance` are relevant for model fitting. In model fitting, the best model is determined using the [auto.ARIMA algorithm](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-time-series#auto_arima) for each time series individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "NAlyHOOjBxRV",
    "outputId": "c40ebf67-a621-46b0-c9db-e14e907b1cd5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT * FROM ML.EVALUATE(MODEL bqmlforecast.arima_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXY99nSmCnsB"
   },
   "source": [
    "We can see that five models have been trained, one for each product. Each model has its own hyperparameters, and the recognised seasonality for these five models is `WEEKLY` and partly `YEARLY`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mDSGlrDap-C"
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZrj49Nwap-D"
   },
   "source": [
    "We can use [ML.FORECAST](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-forecast) to make predictions that predict the next _n_ values as specified in the `horizon` parameter. We can also optionally change the `confidence_level` to change the percentage of future values that fall within the prediction interval. The forecast data is stored in the DataFrame `dfforecast` so that it can be displayed in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTwgjaITYOx8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery dfforecast\n",
    "\n",
    "DECLARE HORIZON STRING DEFAULT \"30\";\n",
    "DECLARE CONFIDENCE_LEVEL STRING DEFAULT \"0.90\";\n",
    "\n",
    "EXECUTE IMMEDIATE format(\"\"\"\n",
    "    SELECT\n",
    "      *\n",
    "    FROM \n",
    "      ML.FORECAST(MODEL bqmlforecast.arima_model, \n",
    "                  STRUCT(%s AS horizon, \n",
    "                         %s AS confidence_level)\n",
    "                 )\n",
    "    \"\"\",HORIZON,CONFIDENCE_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "YaHX0NWXap-G",
    "outputId": "5bd2bc73-4362-458d-c191-17b07c2dc912",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfforecast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N11NZ1d3ap-I"
   },
   "source": [
    "Since `horizon` is set to 30, the result is 30 x (number of products), with one row per predicted value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5nKk-XQap-I",
    "outputId": "2246f362-c0a7-4bb8-b432-88e066276f7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of rows: {dfforecast.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPdfnofgap-K"
   },
   "source": [
    "#### Visualizing predictions\n",
    "\n",
    "We can append the predictions to the time series and thus get a visual impression of whether the predictions are plausible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PBKzdLi-ap-L",
    "outputId": "08b2165f-7f12-4144-87aa-c4c0363a020f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "itemslist = list(dfhistorical.item_name.unique())\n",
    "\n",
    "for item in itemslist:\n",
    "    datah = dfhistorical[dfhistorical.item_name==item].copy()\n",
    "    dataf = dfforecast[dfforecast.item_name==item].copy()\n",
    "    \n",
    "    plot_historical_and_forecast(input_timeseries = datah, \n",
    "                                 timestamp_col_name = \"date\", \n",
    "                                 data_col_name = \"total_amount_sold\",\n",
    "                                 forecast_output = dataf, \n",
    "                                 actual = None,\n",
    "                                 title = item,\n",
    "                                 plotstartdate = \"2021-01-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UEsngQXap-N"
   },
   "source": [
    "#### Compare to the actual sales\n",
    "\n",
    "We first extract the actual sales from the comparative period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-K52as0ap-O",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery dfactual --params $ARIMA_PARAMS\n",
    "\n",
    "DECLARE HORIZON STRING DEFAULT \"30\";\n",
    "\n",
    "SELECT \n",
    "    date,\n",
    "    item_description AS item_name,\n",
    "    SUM(bottles_sold) AS total_amount_sold\n",
    "FROM\n",
    "    `bigquery-public-data.iowa_liquor_sales.sales` \n",
    "GROUP BY\n",
    "    date, item_name\n",
    "HAVING \n",
    "    date BETWEEN DATE_ADD(@TRAININGDATA_ENDDATE, \n",
    "                              INTERVAL 1 DAY) \n",
    "            AND DATE_ADD(@TRAININGDATA_ENDDATE, \n",
    "                             INTERVAL 1+CAST(HORIZON AS INT64) DAY) \n",
    "ORDER BY\n",
    "    date;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8gcqtwiap-S"
   },
   "source": [
    "We insert the actual sales into the visualisation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5C9tXEvwap-S",
    "outputId": "bec48383-c501-4a12-ed34-fd9b12093bd8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "itemslist = list(dfhistorical.item_name.unique())\n",
    "\n",
    "for item in itemslist:\n",
    "    datah = dfhistorical[dfhistorical.item_name==item].sort_values('date')\n",
    "    dataf = dfforecast[dfforecast.item_name==item].sort_values(['forecast_timestamp'])\n",
    "    dataa = dfactual[dfactual.item_name==item].sort_values('date')\n",
    "    plot_historical_and_forecast(input_timeseries = datah, \n",
    "                             timestamp_col_name = \"date\", \n",
    "                             data_col_name = \"total_amount_sold\", \n",
    "                             forecast_output = dataf, \n",
    "                             actual = dataa,\n",
    "                             title = item,\n",
    "                             plotstartdate = \"2021-06-01\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bqml_retail_demand_forecasting.ipynb",
   "provenance": [
    {
     "file_id": "1nqpuwpP8nDxhcty-JVYirH-zfz0iBm87",
     "timestamp": 1614717584256
    }
   ],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
